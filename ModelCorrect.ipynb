{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10, cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 5,000 random samples\n",
    "sample_size = 5000\n",
    "selected_indices = np.random.choice(x_train_full.shape[0], sample_size, replace=False)\n",
    "x_train_sampled = x_train_full[selected_indices]\n",
    "y_train_sampled = y_train_full[selected_indices]\n",
    "\n",
    "# Normalize images\n",
    "x_train_sampled = x_train_sampled.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train_sampled = to_categorical(y_train_sampled, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Split into train, validation, and test\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x_train_sampled, y_train_sampled, test_size=0.3, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print dataset shapes\n",
    "print(\"Training set shape:\", x_train.shape)\n",
    "print(\"Validation set shape:\", x_val.shape)\n",
    "print(\"Test set shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation setup\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=18,  # Slightly different rotation\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Apply to training data\n",
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####MODEL####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-100 dataset\n",
    "(x_train_cifar100, y_train_cifar100), (x_test_cifar100, y_test_cifar100) = cifar100.load_data()\n",
    "\n",
    "# Normalize images\n",
    "x_train_cifar100 = x_train_cifar100.astype('float32') / 255.0\n",
    "x_test_cifar100 = x_test_cifar100.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train_cifar100 = to_categorical(y_train_cifar100, num_classes=100)\n",
    "y_test_cifar100 = to_categorical(y_test_cifar100, num_classes=100)\n",
    "\n",
    "# Split into train, validation, and test\n",
    "x_train_cifar100, x_val_cifar100, y_train_cifar100, y_val_cifar100 = train_test_split(\n",
    "    x_train_cifar100, y_train_cifar100, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation setup\n",
    "datagen_cifar100 = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen_cifar100.fit(x_train_cifar100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "cifar100_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(100, activation='softmax', kernel_regularizer=l2(0.001))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "cifar100_model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "cifar100_model.summary()\n",
    "\n",
    "# Define EarlyStopping and ReduceLROnPlateau callbacks\n",
    "early_stop_cifar100 = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "lr_scheduler_cifar100 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "\n",
    "# Train the CIFAR-100 model\n",
    "history_cifar100 = cifar100_model.fit(\n",
    "    datagen_cifar100.flow(x_train_cifar100, y_train_cifar100, batch_size=32),\n",
    "    epochs=50,\n",
    "    validation_data=(x_val_cifar100, y_val_cifar100),\n",
    "    callbacks=[early_stop_cifar100, lr_scheduler_cifar100],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on CIFAR-100 test set\n",
    "test_loss_cifar100, test_acc_cifar100 = cifar100_model.evaluate(x_test_cifar100, y_test_cifar100, verbose=1)\n",
    "print(f\"Test Loss (CIFAR-100): {test_loss_cifar100:.4f}\")\n",
    "print(f\"Test Accuracy (CIFAR-100): {test_acc_cifar100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Modify model for CIFAR-10 fine-tuning\n",
    "cifar100_model.pop()\n",
    "cifar100_model.add(Dense(10, activation='softmax', kernel_regularizer=l2(0.002)))\n",
    "\n",
    "# Unfreeze last few layers for fine-tuning\n",
    "for layer in cifar100_model.layers[-10:]:  # Unfreezing last 10 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the fine-tuned model with a lower learning rate\n",
    "cifar100_model.compile(optimizer=Adam(learning_rate=2e-5),\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# Train the fine-tuned model on CIFAR-10\n",
    "tune_history = cifar100_model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=8,\n",
    "    epochs=100,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on CIFAR-10 test set\n",
    "test_loss_tuned, test_acc_tuned = cifar100_model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f\"Test Loss (Fine-tuned on CIFAR-10): {test_loss_tuned:.4f}\")\n",
    "print(f\"Test Accuracy (Fine-tuned on CIFAR-10): {test_acc_tuned:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
